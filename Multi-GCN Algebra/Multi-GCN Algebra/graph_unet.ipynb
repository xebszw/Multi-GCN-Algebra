{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.nn.parameter import Parameter\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.8.1+cpu\n"
     ]
    }
   ],
   "source": [
    "# Experiment parameters\n",
    "batch_size = 32\n",
    "threads = 0\n",
    "lr = 0.005\n",
    "epochs = 40\n",
    "log_interval = 10\n",
    "wdecay = 1e-4\n",
    "dataset = 'proteins'\n",
    "model_name = 'unet'  # 'gcn', 'unet'\n",
    "device = 'cpu'  # 'cuda', 'cpu'\n",
    "visualize = True\n",
    "shuffle_nodes = False\n",
    "n_folds = 10  # 10-fold cross validation\n",
    "seed = 111\n",
    "print('torch', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader and reader\n",
    "class GraphData(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 datareader,\n",
    "                 fold_id,\n",
    "                 split):\n",
    "        self.fold_id = fold_id\n",
    "        self.split = split\n",
    "        self.rnd_state = datareader.rnd_state\n",
    "        self.set_fold(datareader.data, fold_id)\n",
    "\n",
    "    def set_fold(self, data, fold_id):\n",
    "        self.total = len(data['targets'])\n",
    "        self.N_nodes_max = data['N_nodes_max']\n",
    "        self.n_classes = data['n_classes']\n",
    "        self.features_dim = data['features_dim']\n",
    "        self.idx = data['splits'][fold_id][self.split]\n",
    "         # use deepcopy to make sure we don't alter objects in folds\n",
    "        self.labels = copy.deepcopy([data['targets'][i] for i in self.idx])\n",
    "        self.adj_list = copy.deepcopy([data['adj_list'][i] for i in self.idx])\n",
    "        self.features_onehot = copy.deepcopy([data['features_onehot'][i] for i in self.idx])\n",
    "        print('%s: %d/%d' % (self.split.upper(), len(self.labels), len(data['targets'])))\n",
    "        self.indices = np.arange(len(self.idx))  # sample indices for this epoch\n",
    "        \n",
    "    def pad(self, mtx, desired_dim1, desired_dim2=None, value=0):\n",
    "        sz = mtx.shape\n",
    "        assert len(sz) == 2, ('only 2d arrays are supported', sz)\n",
    "        # if np.all(np.array(sz) < desired_dim1 / 3): print('matrix shape is suspiciously small', sz, desired_dim1)\n",
    "        if desired_dim2 is not None:\n",
    "            mtx = np.pad(mtx, ((0, desired_dim1 - sz[0]), (0, desired_dim2 - sz[1])), 'constant', constant_values=value)\n",
    "        else:\n",
    "            mtx = np.pad(mtx, ((0, desired_dim1 - sz[0]), (0, 0)), 'constant', constant_values=value)\n",
    "        return mtx\n",
    "    \n",
    "    def nested_list_to_torch(self, data):\n",
    "        if isinstance(data, dict):\n",
    "            keys = list(data.keys())           \n",
    "        for i in range(len(data)):\n",
    "            if isinstance(data, dict):\n",
    "                i = keys[i]\n",
    "            if isinstance(data[i], np.ndarray):\n",
    "                data[i] = torch.from_numpy(data[i]).float()\n",
    "            elif isinstance(data[i], list):\n",
    "                data[i] = list_to_torch(data[i])\n",
    "        return data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indices[index]\n",
    "        N_nodes_max = self.N_nodes_max\n",
    "        N_nodes = self.adj_list[index].shape[0]\n",
    "        graph_support = np.zeros(self.N_nodes_max)\n",
    "        graph_support[:N_nodes] = 1\n",
    "        return self.nested_list_to_torch([self.pad(self.features_onehot[index].copy(), self.N_nodes_max),  # node_features\n",
    "                                          self.pad(self.adj_list[index], self.N_nodes_max, self.N_nodes_max),  # adjacency matrix\n",
    "                                          graph_support,  # mask with values of 0 for dummy (zero padded) nodes, otherwise 1 \n",
    "                                          N_nodes,\n",
    "                                          int(self.labels[index])])  # convert to torch\n",
    "\n",
    "\n",
    "class DataReader():\n",
    "    '''\n",
    "    Class to read the txt files containing all data of the dataset\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 data_dir,  # folder with txt files\n",
    "                 rnd_state=None,\n",
    "                 use_cont_node_attr=False,  # use or not additional float valued node attributes available in some datasets\n",
    "                 folds=10):\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.rnd_state = np.random.RandomState() if rnd_state is None else rnd_state\n",
    "        self.use_cont_node_attr = use_cont_node_attr\n",
    "        files = os.listdir(self.data_dir)\n",
    "        data = {}\n",
    "        nodes, graphs = self.read_graph_nodes_relations(list(filter(lambda f: f.find('graph_indicator') >= 0, files))[0])\n",
    "        data['features'] = self.read_node_features(list(filter(lambda f: f.find('node_labels') >= 0, files))[0], \n",
    "                                                 nodes, graphs, fn=lambda s: int(s.strip()))  \n",
    "        data['adj_list'] = self.read_graph_adj(list(filter(lambda f: f.find('_A') >= 0, files))[0], nodes, graphs)                      \n",
    "        data['targets'] = np.array(self.parse_txt_file(list(filter(lambda f: f.find('graph_labels') >= 0, files))[0],\n",
    "                                                       line_parse_fn=lambda s: int(float(s.strip()))))\n",
    "        \n",
    "        if self.use_cont_node_attr:\n",
    "            data['attr'] = self.read_node_features(list(filter(lambda f: f.find('node_attributes') >= 0, files))[0], \n",
    "                                                   nodes, graphs, fn=lambda s: np.array(list(map(float, s.strip().split(',')))))\n",
    "        \n",
    "        features, n_edges, degrees = [], [], []\n",
    "        for sample_id, adj in enumerate(data['adj_list']):\n",
    "            N = len(adj)  # number of nodes\n",
    "            if data['features'] is not None:\n",
    "                assert N == len(data['features'][sample_id]), (N, len(data['features'][sample_id]))\n",
    "            n = np.sum(adj)  # total sum of edges\n",
    "            assert n % 2 == 0, n\n",
    "            n_edges.append( int(n / 2) )  # undirected edges, so need to divide by 2\n",
    "            if not np.allclose(adj, adj.T):\n",
    "                print(sample_id, 'not symmetric')\n",
    "            degrees.extend(list(np.sum(adj, 1)))\n",
    "            features.append(np.array(data['features'][sample_id]))\n",
    "                        \n",
    "        # Create features over graphs as one-hot vectors for each node\n",
    "        features_all = np.concatenate(features)\n",
    "        features_min = features_all.min()\n",
    "        features_dim = int(features_all.max() - features_min + 1)  # number of possible values\n",
    "        \n",
    "        features_onehot = []\n",
    "        for i, x in enumerate(features):\n",
    "            feature_onehot = np.zeros((len(x), features_dim))\n",
    "            for node, value in enumerate(x):\n",
    "                feature_onehot[node, value - features_min] = 1\n",
    "            if self.use_cont_node_attr:\n",
    "                feature_onehot = np.concatenate((feature_onehot, np.array(data['attr'][i])), axis=1)\n",
    "            features_onehot.append(feature_onehot)\n",
    "\n",
    "        if self.use_cont_node_attr:\n",
    "            features_dim = features_onehot[0].shape[1]\n",
    "            \n",
    "        shapes = [len(adj) for adj in data['adj_list']]\n",
    "        labels = data['targets']        # graph class labels\n",
    "        labels -= np.min(labels)        # to start from 0\n",
    "        N_nodes_max = np.max(shapes)    \n",
    "\n",
    "        classes = np.unique(labels)\n",
    "        n_classes = len(classes)\n",
    "\n",
    "        if not np.all(np.diff(classes) == 1):\n",
    "            print('making labels sequential, otherwise pytorch might crash')\n",
    "            labels_new = np.zeros(labels.shape, dtype=labels.dtype) - 1\n",
    "            for lbl in range(n_classes):\n",
    "                labels_new[labels == classes[lbl]] = lbl\n",
    "            labels = labels_new\n",
    "            classes = np.unique(labels)\n",
    "            assert len(np.unique(labels)) == n_classes, np.unique(labels)\n",
    "\n",
    "        print('N nodes avg/std/min/max: \\t%.2f/%.2f/%d/%d' % (np.mean(shapes), np.std(shapes), np.min(shapes), np.max(shapes)))\n",
    "        print('N edges avg/std/min/max: \\t%.2f/%.2f/%d/%d' % (np.mean(n_edges), np.std(n_edges), np.min(n_edges), np.max(n_edges)))\n",
    "        print('Node degree avg/std/min/max: \\t%.2f/%.2f/%d/%d' % (np.mean(degrees), np.std(degrees), np.min(degrees), np.max(degrees)))\n",
    "        print('Node features dim: \\t\\t%d' % features_dim)\n",
    "        print('N classes: \\t\\t\\t%d' % n_classes)\n",
    "        print('Classes: \\t\\t\\t%s' % str(classes))\n",
    "        for lbl in classes:\n",
    "            print('Class %d: \\t\\t\\t%d samples' % (lbl, np.sum(labels == lbl)))\n",
    "\n",
    "        for u in np.unique(features_all):\n",
    "            print('feature {}, count {}/{}'.format(u, np.count_nonzero(features_all == u), len(features_all)))\n",
    "        \n",
    "        N_graphs = len(labels)  # number of samples (graphs) in data\n",
    "        assert N_graphs == len(data['adj_list']) == len(features_onehot), 'invalid data'\n",
    "\n",
    "        # Create test sets first\n",
    "        train_ids, test_ids = self.split_ids(np.arange(N_graphs), rnd_state=self.rnd_state, folds=folds)\n",
    "\n",
    "        # Create train sets\n",
    "        splits = []\n",
    "        for fold in range(folds):\n",
    "            splits.append({'train': train_ids[fold],\n",
    "                           'test': test_ids[fold]})\n",
    "\n",
    "        data['features_onehot'] = features_onehot\n",
    "        data['targets'] = labels\n",
    "        data['splits'] = splits \n",
    "        data['N_nodes_max'] = np.max(shapes)  # max number of nodes\n",
    "        data['features_dim'] = features_dim\n",
    "        data['n_classes'] = n_classes\n",
    "        \n",
    "        self.data = data\n",
    "\n",
    "    def split_ids(self, ids_all, rnd_state=None, folds=10):\n",
    "        n = len(ids_all)\n",
    "        ids = ids_all[rnd_state.permutation(n)]\n",
    "        stride = int(np.ceil(n / float(folds)))\n",
    "        test_ids = [ids[i: i + stride] for i in range(0, n, stride)]\n",
    "        assert np.all(np.unique(np.concatenate(test_ids)) == sorted(ids_all)), 'some graphs are missing in the test sets'\n",
    "        assert len(test_ids) == folds, 'invalid test sets'\n",
    "        train_ids = []\n",
    "        for fold in range(folds):\n",
    "            train_ids.append(np.array([e for e in ids if e not in test_ids[fold]]))\n",
    "            assert len(train_ids[fold]) + len(test_ids[fold]) == len(np.unique(list(train_ids[fold]) + list(test_ids[fold]))) == n, 'invalid splits'\n",
    "\n",
    "        return train_ids, test_ids\n",
    "\n",
    "    def parse_txt_file(self, fpath, line_parse_fn=None):\n",
    "        with open(pjoin(self.data_dir, fpath), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        data = [line_parse_fn(s) if line_parse_fn is not None else s for s in lines]\n",
    "        return data\n",
    "    \n",
    "    def read_graph_adj(self, fpath, nodes, graphs):\n",
    "        edges = self.parse_txt_file(fpath, line_parse_fn=lambda s: s.split(','))\n",
    "        adj_dict = {}\n",
    "        for edge in edges:\n",
    "            node1 = int(edge[0].strip()) - 1  # -1 because of zero-indexing in our code\n",
    "            node2 = int(edge[1].strip()) - 1\n",
    "            graph_id = nodes[node1]\n",
    "            assert graph_id == nodes[node2], ('invalid data', graph_id, nodes[node2])\n",
    "            if graph_id not in adj_dict:\n",
    "                n = len(graphs[graph_id])\n",
    "                adj_dict[graph_id] = np.zeros((n, n))\n",
    "            ind1 = np.where(graphs[graph_id] == node1)[0]\n",
    "            ind2 = np.where(graphs[graph_id] == node2)[0]\n",
    "            assert len(ind1) == len(ind2) == 1, (ind1, ind2)\n",
    "            adj_dict[graph_id][ind1, ind2] = 1\n",
    "            \n",
    "        adj_list = [adj_dict[graph_id] for graph_id in sorted(list(graphs.keys()))]\n",
    "        \n",
    "        return adj_list\n",
    "        \n",
    "    def read_graph_nodes_relations(self, fpath):\n",
    "        graph_ids = self.parse_txt_file(fpath, line_parse_fn=lambda s: int(s.rstrip()))\n",
    "        nodes, graphs = {}, {}\n",
    "        for node_id, graph_id in enumerate(graph_ids):\n",
    "            if graph_id not in graphs:\n",
    "                graphs[graph_id] = []\n",
    "            graphs[graph_id].append(node_id)\n",
    "            nodes[node_id] = graph_id\n",
    "        graph_ids = np.unique(list(graphs.keys()))\n",
    "        for graph_id in graphs:\n",
    "            graphs[graph_id] = np.array(graphs[graph_id])\n",
    "        return nodes, graphs\n",
    "\n",
    "    def read_node_features(self, fpath, nodes, graphs, fn):\n",
    "        node_features_all = self.parse_txt_file(fpath, line_parse_fn=fn)\n",
    "        node_features = {}\n",
    "        for node_id, x in enumerate(node_features_all):\n",
    "            graph_id = nodes[node_id]\n",
    "            if graph_id not in node_features:\n",
    "                node_features[graph_id] = [ None ] * len(graphs[graph_id])\n",
    "            ind = np.where(graphs[graph_id] == node_id)[0]\n",
    "            assert len(ind) == 1, ind\n",
    "            assert node_features[graph_id][ind[0]] is None, node_features[graph_id][ind[0]]\n",
    "            node_features[graph_id][ind[0]] = x\n",
    "        node_features_lst = [node_features[graph_id] for graph_id in sorted(list(graphs.keys()))]\n",
    "        return node_features_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN layers and models\n",
    "class GraphConv(nn.Module):\n",
    "    '''\n",
    "    Graph Convolution Layer according to (T. Kipf and M. Welling, ICLR 2017)\n",
    "    Additional tricks (power of adjacency matrix and weight self connections) as in the Graph U-Net paper\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                in_features,\n",
    "                out_features,\n",
    "                activation=None,\n",
    "                adj_sq=False,\n",
    "                scale_identity=False):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.fc = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.adj_sq = adj_sq\n",
    "        self.activation = activation\n",
    "        self.scale_identity = scale_identity\n",
    "            \n",
    "    def laplacian_batch(self, A):\n",
    "        batch, N = A.shape[:2]\n",
    "        if self.adj_sq:\n",
    "            A = torch.bmm(A, A)  # use A^2 to increase graph connectivity\n",
    "        I = torch.eye(N).unsqueeze(0).to(device)\n",
    "        if self.scale_identity:\n",
    "            I = 2 * I  # increase weight of self connections\n",
    "        A_hat = A + I\n",
    "        D_hat = (torch.sum(A_hat, 1) + 1e-5) ** (-0.5)\n",
    "        L = D_hat.view(batch, N, 1) * A_hat * D_hat.view(batch, 1, N)\n",
    "        return L\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, A = data[:2]\n",
    "        x = self.fc(torch.bmm(self.laplacian_batch(A), x))\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return (x, A)\n",
    "        \n",
    "class GCN(nn.Module):\n",
    "    '''\n",
    "    Baseline Graph Convolutional Network with a stack of Graph Convolution Layers and global pooling over nodes.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 filters=[64,64,64],\n",
    "                 n_hidden=0,\n",
    "                 dropout=0.2,\n",
    "                 adj_sq=False,\n",
    "                 scale_identity=False):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # Graph convolution layers\n",
    "        self.gconv = nn.Sequential(*([GraphConv(in_features=in_features if layer == 0 else filters[layer - 1], \n",
    "                                                out_features=f, \n",
    "                                                activation=nn.ReLU(inplace=True),\n",
    "                                                adj_sq=adj_sq,\n",
    "                                                scale_identity=scale_identity) for layer, f in enumerate(filters)]))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        fc = []\n",
    "        if dropout > 0:\n",
    "            fc.append(nn.Dropout(p=dropout))\n",
    "        if n_hidden > 0:\n",
    "            fc.append(nn.Linear(filters[-1], n_hidden))\n",
    "            if dropout > 0:\n",
    "                fc.append(nn.Dropout(p=dropout))\n",
    "            n_last = n_hidden\n",
    "        else:\n",
    "            n_last = filters[-1]\n",
    "        fc.append(nn.Linear(n_last, out_features))       \n",
    "        self.fc = nn.Sequential(*fc)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = self.gconv(data)[0]\n",
    "        x = torch.max(x, dim=1)[0].squeeze()  # max pooling over nodes\n",
    "        x = self.fc(x)\n",
    "        return x  \n",
    "    \n",
    "class GraphUnet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 filters=[64,64,64],\n",
    "                 n_hidden=0,\n",
    "                 dropout=0.2,\n",
    "                 adj_sq=False,\n",
    "                 scale_identity=False,\n",
    "                 shuffle_nodes=False,\n",
    "                 visualize=False,\n",
    "                 pooling_ratios=[0.8, 0.8]):\n",
    "        super(GraphUnet, self).__init__()\n",
    "\n",
    "        self.shuffle_nodes = shuffle_nodes\n",
    "        self.visualize = visualize\n",
    "        self.pooling_ratios = pooling_ratios\n",
    "        # Graph convolution layers\n",
    "        self.gconv = nn.ModuleList([GraphConv(in_features=in_features if layer == 0 else filters[layer - 1], \n",
    "                                                out_features=f, \n",
    "                                                activation=nn.ReLU(inplace=True),\n",
    "                                               adj_sq=adj_sq,\n",
    "                                               scale_identity=scale_identity) for layer, f in enumerate(filters)])\n",
    "        # Pooling layers\n",
    "        self.proj = []\n",
    "        for layer, f in enumerate(filters[:-1]):\n",
    "            # Initialize projection vectors similar to weight/bias initialization in nn.Linear\n",
    "            fan_in = filters[layer]\n",
    "            p = Parameter(torch.Tensor(fan_in, 1))\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            torch.nn.init.uniform_(p, -bound, bound)\n",
    "            self.proj.append(p)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        fc = []\n",
    "        if dropout > 0:\n",
    "            fc.append(nn.Dropout(p=dropout))\n",
    "        if n_hidden > 0:\n",
    "            fc.append(nn.Linear(filters[-1], n_hidden))\n",
    "            if dropout > 0:\n",
    "                fc.append(nn.Dropout(p=dropout))\n",
    "            n_last = n_hidden\n",
    "        else:\n",
    "            n_last = filters[-1]\n",
    "        fc.append(nn.Linear(n_last, out_features))       \n",
    "        self.fc = nn.Sequential(*fc)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # [signal, W, signal_support, N_nodes, int(label)]\n",
    "        if self.shuffle_nodes:\n",
    "            N = data[0].shape[1]\n",
    "            idx = torch.randperm(N)\n",
    "            data = (data[0][:, idx], data[1][:, idx][idx, :], data[2][:, idx], data[3])\n",
    "        plot = -1\n",
    "        N_nodes_tmp = -1\n",
    "        for layer, gconv in enumerate(self.gconv):\n",
    "            N_nodes = data[3]\n",
    "            N_nodes_max = N_nodes.max()\n",
    "            #print('layer', layer, N_nodes_max)\n",
    "            #data = (data[0][:, :N_nodes_max], data[1][:, :N_nodes_max, :N_nodes_max], data[2][:, :N_nodes_max], data[3])      \n",
    "            B, N, _ = data[0].shape\n",
    "            if layer < len(self.gconv) - 1 and self.visualize:      \n",
    "                x, W = data[:2]\n",
    "                for b in range(B):\n",
    "                    if (layer == 0 and N_nodes[b] < 20 and N_nodes[b] > 10) or plot > -1:\n",
    "                        if plot > -1 and plot != b:\n",
    "                            continue\n",
    "                        if N_nodes_tmp < 0:\n",
    "                            N_nodes_tmp = N_nodes[b]\n",
    "                        plt.figure(figsize=(18,5))\n",
    "                        plt.subplot(141)\n",
    "                        plt.title('layer %d, Input adjacency matrix' % (layer))\n",
    "                        plt.imshow(W[b][:N_nodes_tmp, :N_nodes_tmp].data.cpu().numpy())\n",
    "                        plot = b                        \n",
    "                        break\n",
    "            mask = data[2].clone()\n",
    "            data = gconv(data)\n",
    "            x, W = data\n",
    "            if layer < len(self.gconv) - 1:\n",
    "                B, N, C = x.shape\n",
    "                y = torch.mm(x.view(B * N, C), self.proj[layer]).view(B, N)\n",
    "                y = y / (torch.sum(self.proj[layer] ** 2).view(1, 1) ** 0.5)  # node scores used for ranking below\n",
    "                idx = torch.sort(y, dim=1)[1]  # B,N                \n",
    "                N_remove = (N_nodes.float() * (1 - self.pooling_ratios[layer])).long()\n",
    "                assert torch.all(N_nodes > N_remove), 'the number of removed nodes must be large than the number of nodes'\n",
    "                for b in range(B):\n",
    "                    assert torch.sum(mask[b]) == float(N_nodes[b]), (torch.sum(mask[b]), N_nodes[b])\n",
    "                N_nodes_prev = N_nodes\n",
    "                N_nodes = N_nodes - N_remove\n",
    "                                \n",
    "                for b in range(B):\n",
    "                    idx_b = idx[b, mask[b, idx[b]] == 1]\n",
    "                    assert len(idx_b) >= N_nodes[b], (len(idx_b), N_nodes[b])\n",
    "                    mask[b, idx_b[:N_remove[b]]] = 0\n",
    "                for b in range(B):\n",
    "                    assert torch.sum(mask[b]) == float(N_nodes[b]), (b, torch.sum(mask[b]), N_nodes[b], N_remove[b], N_nodes_prev[b])\n",
    "                    s = torch.sum(y[b] >= torch.min((y * mask.float())[b]))\n",
    "                    assert s >= float(N_nodes[b]), (s, N_nodes[b], (y * mask.float())[b])\n",
    "                \n",
    "                mask = mask.unsqueeze(2)\n",
    "                x = x * torch.tanh(y).unsqueeze(2) * mask\n",
    "                W = mask * W * mask.view(B, 1, N)\n",
    "                mask = mask.squeeze()\n",
    "                data = (x, W, mask, N_nodes)\n",
    "                \n",
    "                if self.visualize and plot > -1:\n",
    "                    b = plot\n",
    "                    plt.subplot(142)\n",
    "                    plt.title('layer %d, Ranking' % (layer))\n",
    "                    plt.imshow(y[b].view(N, 1).expand(N, 2)[:N_nodes_tmp].data.cpu().numpy())\n",
    "                    plt.colorbar()\n",
    "                    plt.subplot(143)\n",
    "                    plt.title('layer %d, Pooled nodes (%d/%d)' % (layer, mask[b].sum(), N_nodes_prev[b]))\n",
    "                    plt.imshow(mask[b].view(N, 1).expand(N, 2)[:N_nodes_tmp].data.cpu().numpy())\n",
    "                    plt.subplot(144)\n",
    "                    plt.title('layer %d, Pooled adjacency matrix' % (layer))\n",
    "                    plt.imshow(W[b][:N_nodes_tmp, :N_nodes_tmp].data.cpu().numpy())\n",
    "                    plt.show()\n",
    "                        \n",
    "        if self.visualize and plot > -1:\n",
    "            self.visualize = False\n",
    "        x = torch.max(x, dim=1)[0].squeeze()  # max pooling over nodes\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "N nodes avg/std/min/max: \t39.06/45.76/4/620\n",
      "N edges avg/std/min/max: \t72.82/84.60/5/1049\n",
      "Node degree avg/std/min/max: \t3.73/1.15/0/25\n",
      "Node features dim: \t\t3\n",
      "N classes: \t\t\t2\n",
      "Classes: \t\t\t[0 1]\n",
      "Class 0: \t\t\t663 samples\n",
      "Class 1: \t\t\t450 samples\n",
      "feature 0, count 21151/43471\n",
      "feature 1, count 20931/43471\n",
      "feature 2, count 1389/43471\n",
      "\n",
      "FOLD 0\n",
      "TRAIN: 1001/1113\n",
      "TEST: 112/1113\n",
      "\n",
      "Initialize model\n",
      "GraphUnet(\n",
      "  (gconv): ModuleList(\n",
      "    (0): GraphConv(\n",
      "      (fc): Linear(in_features=3, out_features=64, bias=True)\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): GraphConv(\n",
      "      (fc): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): GraphConv(\n",
      "      (fc): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "N trainable parameters: 8706\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [32/1001 (3%)]\tLoss: 0.687614 (avg: 0.687614) \tsec/iter: 1.1869\n",
      "Train Epoch: 0 [352/1001 (34%)]\tLoss: 0.704223 (avg: 0.678780) \tsec/iter: 0.4468\n",
      "Train Epoch: 0 [672/1001 (66%)]\tLoss: 0.635130 (avg: 0.690568) \tsec/iter: 0.4084\n",
      "Train Epoch: 0 [992/1001 (97%)]\tLoss: 0.659696 (avg: 0.685526) \tsec/iter: 0.3952\n",
      "Train Epoch: 0 [1001/1001 (100%)]\tLoss: 0.707856 (avg: 0.685727) \tsec/iter: 0.3866\n",
      "Test set (epoch 0): Average loss: 0.6676, Accuracy: 597/1001 (59.64%)\n",
      "\n",
      "Train Epoch: 1 [32/1001 (3%)]\tLoss: 0.662708 (avg: 0.662708) \tsec/iter: 0.4219\n",
      "Train Epoch: 1 [352/1001 (34%)]\tLoss: 0.636778 (avg: 0.658304) \tsec/iter: 0.3824\n",
      "Train Epoch: 1 [672/1001 (66%)]\tLoss: 0.663739 (avg: 0.668152) \tsec/iter: 0.3978\n",
      "Train Epoch: 1 [992/1001 (97%)]\tLoss: 0.631264 (avg: 0.666279) \tsec/iter: 0.3912\n",
      "Train Epoch: 1 [1001/1001 (100%)]\tLoss: 0.490305 (avg: 0.664697) \tsec/iter: 0.3827\n",
      "Test set (epoch 1): Average loss: 0.6789, Accuracy: 597/1001 (59.64%)\n",
      "\n",
      "Train Epoch: 2 [32/1001 (3%)]\tLoss: 0.533173 (avg: 0.533173) \tsec/iter: 0.4543\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bbbe72f928b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0macc_folds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-bbbe72f928b7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a210588ef4f2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    153\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgconv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a210588ef4f2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplacian_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a210588ef4f2>\u001b[0m in \u001b[0;36mlaplacian_batch\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mA_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mD_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mA_hat\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mD_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "datareader = DataReader(data_dir='./data/%s/' % dataset.upper(),\n",
    "                        rnd_state=np.random.RandomState(seed),\n",
    "                        folds=n_folds,                    \n",
    "                        use_cont_node_attr=False)\n",
    "\n",
    "acc_folds = []\n",
    "for fold_id in range(n_folds):\n",
    "    print('\\nFOLD', fold_id)\n",
    "    loaders = []\n",
    "    for split in ['train', 'test']:\n",
    "        gdata = GraphData(fold_id=fold_id,\n",
    "                             datareader=datareader,\n",
    "                             split=split)\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(gdata, \n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=split.find('train') >= 0,\n",
    "                                             num_workers=threads)\n",
    "        loaders.append(loader)\n",
    "    \n",
    "    if model_name == 'gcn':\n",
    "        model = GCN(in_features=loaders[0].dataset.features_dim,\n",
    "                    out_features=loaders[0].dataset.n_classes,\n",
    "                    n_hidden=0,\n",
    "                    filters=[64,64,64],\n",
    "                    dropout=0.2,\n",
    "                    adj_sq=False,\n",
    "                    scale_identity=False).to(device)\n",
    "    elif model_name == 'unet':\n",
    "        model = GraphUnet(in_features=loaders[0].dataset.features_dim,\n",
    "                          out_features=loaders[0].dataset.n_classes,\n",
    "                          n_hidden=0,\n",
    "                          filters=[64,64,64],\n",
    "                          dropout=0.2,\n",
    "                          adj_sq=False,\n",
    "                          scale_identity=False,\n",
    "                          shuffle_nodes=shuffle_nodes,\n",
    "                          visualize=visualize).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(model_name)\n",
    "\n",
    "    print('\\nInitialize model')\n",
    "    print(model)\n",
    "    c = 0\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        c += p.numel()\n",
    "    print('N trainable parameters:', c)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                lr=lr,\n",
    "                weight_decay=wdecay,\n",
    "                betas=(0.5, 0.999))\n",
    "    \n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, [20, 30], gamma=0.1)\n",
    "\n",
    "    def train(train_loader):\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        start = time.time()\n",
    "        train_loss, n_samples = 0, 0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data[4])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            time_iter = time.time() - start\n",
    "            train_loss += loss.item() * len(output)\n",
    "            n_samples += len(output)\n",
    "            if batch_idx % log_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} (avg: {:.6f}) \\tsec/iter: {:.4f}'.format(\n",
    "                    epoch, n_samples, len(train_loader.dataset),\n",
    "                    100. * (batch_idx + 1) / len(train_loader), loss.item(), train_loss / n_samples, time_iter / (batch_idx + 1) ))\n",
    "    #             break \n",
    "    def test(test_loader):\n",
    "        model.eval()\n",
    "        start = time.time()\n",
    "        test_loss, correct, n_samples = 0, 0, 0\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data[4], reduction='sum')\n",
    "            test_loss += loss.item()\n",
    "            n_samples += len(output)\n",
    "            pred = output.detach().cpu().max(1, keepdim=True)[1]\n",
    "\n",
    "            correct += pred.eq(data[4].detach().cpu().view_as(pred)).sum().item()\n",
    "\n",
    "        time_iter = time.time() - start\n",
    "\n",
    "        test_loss /= n_samples\n",
    "\n",
    "        acc = 100. * correct / n_samples\n",
    "        print('Test set (epoch {}): Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(epoch, \n",
    "                                                                                              test_loss, \n",
    "                                                                                              correct, \n",
    "                                                                                              n_samples, acc))\n",
    "        return acc\n",
    "\n",
    "    loss_fn = F.cross_entropy\n",
    "    for epoch in range(epochs):\n",
    "        train(loaders[0])\n",
    "        acc = test(loaders[0])\n",
    "    acc_folds.append(acc)\n",
    "\n",
    "print(acc_folds)\n",
    "print('{}-fold cross validation avg acc (+- std): {} ({})'.format(n_folds, np.mean(acc_folds), np.std(acc_folds)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "433e6f1ab604dbe4f4c3ec179a66ed24ace19cf54eb0a1c8e952dd406fca9fba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
